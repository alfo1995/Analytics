{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics seconda prova Giugno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il compito consiste nell’analizzare il dataset Telekom  ed ottenere un modello predittivo in grado di individuare la classe di appartenenza (STATUS, binaria). La legenda è nel file txt  allegato.\n",
    "\n",
    "Le fasi dell’analisi consistono in:\n",
    "\n",
    "1) Preprocessing dei dati (trasformazioni, ricodifiche, selezione) imputare le variabili che hanno missing\n",
    "\n",
    "2) Individuazione del modello ottimale, scegliendo tra quelli conosciuti (Alberi, gradient boosting, foreste random, logistico, reti neurali, ….)\n",
    "\n",
    "3) Risultati di valutazione(a scelta tra hold-out o cross-validation): matrici di confusione e AUC nel training e nel test (o cross-validation), curva ROC.\n",
    "\n",
    "4) Provare a bilanciare la target e verificare la differenza nei risultati \n",
    "\n",
    "5) Valutare sinteticamente (10 righe) i risultati ottenuti\n",
    "\n",
    "**I risultati e i commenti devono essere messi in un file .doc di cui dovete effettuare l'upload**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo le librerie di alto livello di cui avrò bisogno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer,LabelEncoder,OneHotEncoder,StandardScaler\n",
    "from sklearn.cross_validation import cross_val_score,cross_val_predict,train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,roc_curve,classification_report\n",
    "from keras import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Activation,BatchNormalization,Dropout,Dense\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('./telekom.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>piano_tariff</th>\n",
       "      <th>metodo_pagamento</th>\n",
       "      <th>sesso</th>\n",
       "      <th>etacl</th>\n",
       "      <th>zona_attivaz</th>\n",
       "      <th>canale_attivaz</th>\n",
       "      <th>vas1</th>\n",
       "      <th>vas2</th>\n",
       "      <th>q01_out_ch_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>q01_in_dur_tot</th>\n",
       "      <th>q01_ch_sms</th>\n",
       "      <th>q09_out_ch_peak</th>\n",
       "      <th>q09_out_dur_peak</th>\n",
       "      <th>q09_out_val_peak</th>\n",
       "      <th>q09_out_dur_offpeak</th>\n",
       "      <th>q09_out_val_offpeak</th>\n",
       "      <th>q09_in_ch_tot</th>\n",
       "      <th>q09_in_dur_tot</th>\n",
       "      <th>q09_ch_sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30.75</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>2162</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>5190</td>\n",
       "      <td>34.6450</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123</td>\n",
       "      <td>10715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.78</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>719</td>\n",
       "      <td>4.8191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>3115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19.80</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.1168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170</td>\n",
       "      <td>14807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>21.67</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>7216</td>\n",
       "      <td>43.6824</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>3334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  piano_tariff  metodo_pagamento  sesso  etacl  zona_attivaz  \\\n",
       "0       0             8                 3      3  30.75             3   \n",
       "1       0             8                 1      3  20.78             2   \n",
       "2       0             7                 3      3  19.80             1   \n",
       "3       0             8                 2      3  21.67             1   \n",
       "4       0             8                 2      1  24.75             1   \n",
       "\n",
       "   canale_attivaz  vas1  vas2  q01_out_ch_peak     ...      q01_in_dur_tot  \\\n",
       "0               5     1     1               45     ...                2162   \n",
       "1               5     1     1                0     ...                   0   \n",
       "2               5     1     1                0     ...                   0   \n",
       "3               9     1     1                0     ...                   0   \n",
       "4               5     1     1                0     ...                   0   \n",
       "\n",
       "   q01_ch_sms  q09_out_ch_peak  q09_out_dur_peak  q09_out_val_peak  \\\n",
       "0           0               78              5190           34.6450   \n",
       "1           0               11               719            4.8191   \n",
       "2           0               50              2665           14.1168   \n",
       "3           0               65              7216           43.6824   \n",
       "4           0                0                 0            0.0000   \n",
       "\n",
       "   q09_out_dur_offpeak  q09_out_val_offpeak  q09_in_ch_tot  q09_in_dur_tot  \\\n",
       "0                    0                  0.0            123           10715   \n",
       "1                    0                  0.0             31            3115   \n",
       "2                    0                  0.0            170           14807   \n",
       "3                    0                  0.0             25            3334   \n",
       "4                    0                  0.0              0               0   \n",
       "\n",
       "   q09_ch_sms  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#guardo le prime righe del dataset e rimuovo la variabile ID inutile ai fini della classificazione.\n",
    "dataset=dataset.drop('ID',axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vediamo se ci sono variabili con Na's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.isnull().values.any())\n",
    "print(dataset.columns[dataset.isnull().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leggendo la descrizione delle variabili emerge che:\n",
    "- non ci sono variabili qualitative sul quale applicare Label Encoder\n",
    "- Le variabili (features) categoriche sul quale applicare l'encoding sono:\n",
    "        + piano_tariff\n",
    "        + metodo_pagamento\n",
    "        + sesso\n",
    "        + zona_attivaz\n",
    "        + canale_attivaz\n",
    "        + vas1\n",
    "        + vas2\n",
    "- Le restanti variabili sono numeriche \n",
    "- La variabile 'status' è la nostra **variabile risposta $y$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***encoding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,columns=['piano_tariff','metodo_pagamento','sesso'\n",
    "                                        ,'zona_attivaz','canale_attivaz','vas1','vas2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora divido il dataset in $X$ ed $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.drop('status',axis=1).values\n",
    "y=dataset['status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provo a selezionare con SelectKbest, le 20 variabili migliori tramite il calcolo del chi2\n",
    "#X_new = SelectKBest(chi2, k=20).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto utilizzo la tecnica dell'HOLD OUT per dividere il dataset in Train e Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho deciso di utilizzare tre modelli e confrontarli tra loro:\n",
    "- Random Forest classifier\n",
    "- Gradient Boosting classifier\n",
    "    - eventualmente faccio il tuning dei parametri con Grid Search\n",
    "- Neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#scale the X coloumns\n",
    "sc_X = StandardScaler()\n",
    "#for the training set we need to fit it, then scale it\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANDOM FOREST CLASSIFIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953373768006\n",
      "\n",
      "Confusion matrix:\n",
      "[[1590   81]\n",
      " [  42  925]]\n",
      "\n",
      "auc: 0.989547396991\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "RFC=RandomForestClassifier()\n",
    "RFC.fit(X_train,y_train)\n",
    "y_pred=RFC.predict(X_test)\n",
    "\n",
    "#calcolo accuracy\n",
    "accuracy=accuracy_score(y_pred,y_test)\n",
    "print('Accuracy: '+str(accuracy))\n",
    "print()\n",
    "print('Confusion matrix:')\n",
    "cm=confusion_matrix(y_pred,y_test)\n",
    "print(cm)\n",
    "\n",
    "y_pred_proba = RFC.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print()\n",
    "print(\"auc: \"+str(auc))\n",
    "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve Random Forest')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "RF_out=[accuracy,auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRADIENT BOOSTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.974981046247\n",
      "\n",
      "Confusion matrix:\n",
      "[[1593   27]\n",
      " [  39  979]]\n",
      "\n",
      "auc: 0.989547396991\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GB=GradientBoostingClassifier()\n",
    "GB.fit(X_train,y_train)\n",
    "y_pred=GB.predict(X_test)\n",
    "\n",
    "#calcolo accuracy\n",
    "accuracy=accuracy_score(y_pred,y_test)\n",
    "print('Accuracy: '+str(accuracy))\n",
    "print()\n",
    "print('Confusion matrix:')\n",
    "cm=confusion_matrix(y_pred,y_test)\n",
    "print(cm)\n",
    "\n",
    "y_pred_proba = RFC.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print()\n",
    "print(\"auc: \"+str(auc))\n",
    "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve Random Forest')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "GB_out=[accuracy,auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RETE NEURALE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6154/6154 [==============================] - 1s 103us/step - loss: 0.6587 - acc: 0.6176\n",
      "Epoch 2/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.4864 - acc: 0.6280\n",
      "Epoch 3/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.3918 - acc: 0.8694\n",
      "Epoch 4/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.3553 - acc: 0.9118\n",
      "Epoch 5/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.3333 - acc: 0.9054\n",
      "Epoch 6/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.3119 - acc: 0.9204\n",
      "Epoch 7/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2849 - acc: 0.9251\n",
      "Epoch 8/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2699 - acc: 0.9279\n",
      "Epoch 9/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2635 - acc: 0.9285\n",
      "Epoch 10/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2493 - acc: 0.9363\n",
      "Epoch 11/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2329 - acc: 0.9418\n",
      "Epoch 12/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2312 - acc: 0.9357\n",
      "Epoch 13/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2156 - acc: 0.9475\n",
      "Epoch 14/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2103 - acc: 0.9446\n",
      "Epoch 15/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.2014 - acc: 0.9459\n",
      "Epoch 16/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1989 - acc: 0.9448\n",
      "Epoch 17/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1889 - acc: 0.9448\n",
      "Epoch 18/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1817 - acc: 0.9496\n",
      "Epoch 19/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1784 - acc: 0.9487\n",
      "Epoch 20/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1739 - acc: 0.9532\n",
      "Epoch 21/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1769 - acc: 0.9470\n",
      "Epoch 22/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1687 - acc: 0.9483\n",
      "Epoch 23/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1653 - acc: 0.9506\n",
      "Epoch 24/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1542 - acc: 0.9553\n",
      "Epoch 25/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1622 - acc: 0.9526\n",
      "Epoch 26/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1575 - acc: 0.9516\n",
      "Epoch 27/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1587 - acc: 0.9516\n",
      "Epoch 28/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1552 - acc: 0.9519\n",
      "Epoch 29/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1491 - acc: 0.9537\n",
      "Epoch 30/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1581 - acc: 0.9501\n",
      "Epoch 31/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1433 - acc: 0.9558\n",
      "Epoch 32/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1535 - acc: 0.9519\n",
      "Epoch 33/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1465 - acc: 0.9540\n",
      "Epoch 34/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1380 - acc: 0.9568\n",
      "Epoch 35/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1487 - acc: 0.9521\n",
      "Epoch 36/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1414 - acc: 0.9553\n",
      "Epoch 37/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1385 - acc: 0.9552\n",
      "Epoch 38/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1429 - acc: 0.9550\n",
      "Epoch 39/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1430 - acc: 0.9527\n",
      "Epoch 40/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1463 - acc: 0.9527\n",
      "Epoch 41/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1381 - acc: 0.9579\n",
      "Epoch 42/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1385 - acc: 0.9545\n",
      "Epoch 43/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1379 - acc: 0.9556\n",
      "Epoch 44/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1397 - acc: 0.9537\n",
      "Epoch 45/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1332 - acc: 0.9579\n",
      "Epoch 46/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1382 - acc: 0.9556\n",
      "Epoch 47/200\n",
      "6154/6154 [==============================] - 0s 22us/step - loss: 0.1288 - acc: 0.9569\n",
      "Epoch 48/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1323 - acc: 0.9573\n",
      "Epoch 49/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1412 - acc: 0.9521\n",
      "Epoch 50/200\n",
      "6154/6154 [==============================] - 0s 35us/step - loss: 0.1252 - acc: 0.9621\n",
      "Epoch 51/200\n",
      "6154/6154 [==============================] - 0s 33us/step - loss: 0.1427 - acc: 0.9524\n",
      "Epoch 52/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1339 - acc: 0.9573\n",
      "Epoch 53/200\n",
      "6154/6154 [==============================] - 0s 29us/step - loss: 0.1365 - acc: 0.9576\n",
      "Epoch 54/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1340 - acc: 0.9553\n",
      "Epoch 55/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1265 - acc: 0.9607\n",
      "Epoch 56/200\n",
      "6154/6154 [==============================] - 0s 22us/step - loss: 0.1342 - acc: 0.9571\n",
      "Epoch 57/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1373 - acc: 0.9579\n",
      "Epoch 58/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1332 - acc: 0.9602\n",
      "Epoch 59/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1266 - acc: 0.9591\n",
      "Epoch 60/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1340 - acc: 0.9576\n",
      "Epoch 61/200\n",
      "6154/6154 [==============================] - 0s 23us/step - loss: 0.1398 - acc: 0.9540\n",
      "Epoch 62/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1366 - acc: 0.9573\n",
      "Epoch 63/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1281 - acc: 0.9587\n",
      "Epoch 64/200\n",
      "6154/6154 [==============================] - 0s 30us/step - loss: 0.1258 - acc: 0.9599\n",
      "Epoch 65/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1279 - acc: 0.9623\n",
      "Epoch 66/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1291 - acc: 0.9582\n",
      "Epoch 67/200\n",
      "6154/6154 [==============================] - 0s 23us/step - loss: 0.1368 - acc: 0.9560\n",
      "Epoch 68/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1351 - acc: 0.9563\n",
      "Epoch 69/200\n",
      "6154/6154 [==============================] - 0s 22us/step - loss: 0.1208 - acc: 0.9621\n",
      "Epoch 70/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1330 - acc: 0.9589\n",
      "Epoch 71/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1193 - acc: 0.9621\n",
      "Epoch 72/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1242 - acc: 0.9607\n",
      "Epoch 73/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1233 - acc: 0.9620\n",
      "Epoch 74/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1237 - acc: 0.9617\n",
      "Epoch 75/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1243 - acc: 0.9618\n",
      "Epoch 76/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1229 - acc: 0.9630\n",
      "Epoch 77/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1261 - acc: 0.9597\n",
      "Epoch 78/200\n",
      "6154/6154 [==============================] - 0s 23us/step - loss: 0.1343 - acc: 0.9574\n",
      "Epoch 79/200\n",
      "6154/6154 [==============================] - 0s 33us/step - loss: 0.1379 - acc: 0.9555\n",
      "Epoch 80/200\n",
      "6154/6154 [==============================] - 0s 30us/step - loss: 0.1426 - acc: 0.9543\n",
      "Epoch 81/200\n",
      "6154/6154 [==============================] - 0s 30us/step - loss: 0.1399 - acc: 0.9573\n",
      "Epoch 82/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1336 - acc: 0.9569\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6154/6154 [==============================] - 0s 27us/step - loss: 0.1325 - acc: 0.9579\n",
      "Epoch 84/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1294 - acc: 0.9602\n",
      "Epoch 85/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1301 - acc: 0.9600\n",
      "Epoch 86/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1250 - acc: 0.9594\n",
      "Epoch 87/200\n",
      "6154/6154 [==============================] - 0s 23us/step - loss: 0.1266 - acc: 0.9602\n",
      "Epoch 88/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1231 - acc: 0.9623\n",
      "Epoch 89/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1379 - acc: 0.9558\n",
      "Epoch 90/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1303 - acc: 0.9594\n",
      "Epoch 91/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1276 - acc: 0.9599\n",
      "Epoch 92/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1226 - acc: 0.9615\n",
      "Epoch 93/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1089 - acc: 0.9670\n",
      "Epoch 94/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1225 - acc: 0.9617\n",
      "Epoch 95/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1151 - acc: 0.9660\n",
      "Epoch 96/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1269 - acc: 0.9602\n",
      "Epoch 97/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1190 - acc: 0.9649\n",
      "Epoch 98/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1293 - acc: 0.9591\n",
      "Epoch 99/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1369 - acc: 0.9553\n",
      "Epoch 100/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1240 - acc: 0.9602\n",
      "Epoch 101/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1166 - acc: 0.9646\n",
      "Epoch 102/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1185 - acc: 0.9639\n",
      "Epoch 103/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1224 - acc: 0.9607\n",
      "Epoch 104/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1193 - acc: 0.9643\n",
      "Epoch 105/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1225 - acc: 0.9647\n",
      "Epoch 106/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1191 - acc: 0.9630\n",
      "Epoch 107/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1265 - acc: 0.9595\n",
      "Epoch 108/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1186 - acc: 0.9652\n",
      "Epoch 109/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1230 - acc: 0.9626\n",
      "Epoch 110/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1216 - acc: 0.9617\n",
      "Epoch 111/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1168 - acc: 0.9656\n",
      "Epoch 112/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1193 - acc: 0.9638\n",
      "Epoch 113/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1161 - acc: 0.9649\n",
      "Epoch 114/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1122 - acc: 0.9670\n",
      "Epoch 115/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1277 - acc: 0.9613\n",
      "Epoch 116/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1277 - acc: 0.9617\n",
      "Epoch 117/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1189 - acc: 0.9636\n",
      "Epoch 118/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1251 - acc: 0.9612\n",
      "Epoch 119/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1148 - acc: 0.9638\n",
      "Epoch 120/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1246 - acc: 0.9634\n",
      "Epoch 121/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1165 - acc: 0.9643\n",
      "Epoch 122/200\n",
      "6154/6154 [==============================] - 0s 29us/step - loss: 0.1272 - acc: 0.9610\n",
      "Epoch 123/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1162 - acc: 0.9644\n",
      "Epoch 124/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1225 - acc: 0.9618\n",
      "Epoch 125/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1247 - acc: 0.9605\n",
      "Epoch 126/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1217 - acc: 0.9618\n",
      "Epoch 127/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1272 - acc: 0.9602\n",
      "Epoch 128/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1361 - acc: 0.9571\n",
      "Epoch 129/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1192 - acc: 0.9633\n",
      "Epoch 130/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1182 - acc: 0.9634\n",
      "Epoch 131/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1305 - acc: 0.9586\n",
      "Epoch 132/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1292 - acc: 0.9595\n",
      "Epoch 133/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1212 - acc: 0.9638\n",
      "Epoch 134/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1214 - acc: 0.9628\n",
      "Epoch 135/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1216 - acc: 0.9633\n",
      "Epoch 136/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1292 - acc: 0.9600\n",
      "Epoch 137/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1215 - acc: 0.9621\n",
      "Epoch 138/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1117 - acc: 0.9664\n",
      "Epoch 139/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1158 - acc: 0.9649\n",
      "Epoch 140/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1194 - acc: 0.9641\n",
      "Epoch 141/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1238 - acc: 0.9607\n",
      "Epoch 142/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1192 - acc: 0.9651\n",
      "Epoch 143/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1143 - acc: 0.9657\n",
      "Epoch 144/200\n",
      "6154/6154 [==============================] - 0s 22us/step - loss: 0.1272 - acc: 0.9610\n",
      "Epoch 145/200\n",
      "6154/6154 [==============================] - 0s 28us/step - loss: 0.1335 - acc: 0.9576\n",
      "Epoch 146/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1258 - acc: 0.9594\n",
      "Epoch 147/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1254 - acc: 0.9617\n",
      "Epoch 148/200\n",
      "6154/6154 [==============================] - 0s 23us/step - loss: 0.1274 - acc: 0.9594\n",
      "Epoch 149/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1194 - acc: 0.9651\n",
      "Epoch 150/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1142 - acc: 0.9652\n",
      "Epoch 151/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1202 - acc: 0.9628\n",
      "Epoch 152/200\n",
      "6154/6154 [==============================] - 0s 23us/step - loss: 0.1258 - acc: 0.9623\n",
      "Epoch 153/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1258 - acc: 0.9608\n",
      "Epoch 154/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1223 - acc: 0.9630\n",
      "Epoch 155/200\n",
      "6154/6154 [==============================] - 0s 22us/step - loss: 0.1198 - acc: 0.9621\n",
      "Epoch 156/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1274 - acc: 0.9599\n",
      "Epoch 157/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1178 - acc: 0.9623\n",
      "Epoch 158/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1208 - acc: 0.9618\n",
      "Epoch 159/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1221 - acc: 0.9612\n",
      "Epoch 160/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1148 - acc: 0.9665\n",
      "Epoch 161/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1168 - acc: 0.9643\n",
      "Epoch 162/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1233 - acc: 0.9617\n",
      "Epoch 163/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1091 - acc: 0.9662\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1246 - acc: 0.9604\n",
      "Epoch 165/200\n",
      "6154/6154 [==============================] - 0s 22us/step - loss: 0.1138 - acc: 0.9656\n",
      "Epoch 166/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1133 - acc: 0.9664\n",
      "Epoch 167/200\n",
      "6154/6154 [==============================] - 0s 26us/step - loss: 0.1129 - acc: 0.9659\n",
      "Epoch 168/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1330 - acc: 0.9602\n",
      "Epoch 169/200\n",
      "6154/6154 [==============================] - 0s 27us/step - loss: 0.1227 - acc: 0.9608\n",
      "Epoch 170/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1160 - acc: 0.9641\n",
      "Epoch 171/200\n",
      "6154/6154 [==============================] - 0s 29us/step - loss: 0.1229 - acc: 0.9625\n",
      "Epoch 172/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1164 - acc: 0.9649\n",
      "Epoch 173/200\n",
      "6154/6154 [==============================] - 0s 20us/step - loss: 0.1233 - acc: 0.9626\n",
      "Epoch 174/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1194 - acc: 0.9631\n",
      "Epoch 175/200\n",
      "6154/6154 [==============================] - 0s 27us/step - loss: 0.1155 - acc: 0.9646\n",
      "Epoch 176/200\n",
      "6154/6154 [==============================] - 0s 28us/step - loss: 0.1268 - acc: 0.9599\n",
      "Epoch 177/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1127 - acc: 0.9656\n",
      "Epoch 178/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1171 - acc: 0.9643\n",
      "Epoch 179/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1202 - acc: 0.9643\n",
      "Epoch 180/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1225 - acc: 0.9634\n",
      "Epoch 181/200\n",
      "6154/6154 [==============================] - 0s 21us/step - loss: 0.1156 - acc: 0.9657\n",
      "Epoch 182/200\n",
      "6154/6154 [==============================] - 0s 23us/step - loss: 0.1240 - acc: 0.9615\n",
      "Epoch 183/200\n",
      "6154/6154 [==============================] - 0s 19us/step - loss: 0.1273 - acc: 0.9595\n",
      "Epoch 184/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1170 - acc: 0.9636\n",
      "Epoch 185/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1264 - acc: 0.9610\n",
      "Epoch 186/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1211 - acc: 0.9633\n",
      "Epoch 187/200\n",
      "6154/6154 [==============================] - 0s 25us/step - loss: 0.1147 - acc: 0.9660\n",
      "Epoch 188/200\n",
      "6154/6154 [==============================] - 0s 24us/step - loss: 0.1190 - acc: 0.9652\n",
      "Epoch 189/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1137 - acc: 0.9638\n",
      "Epoch 190/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1122 - acc: 0.9657\n",
      "Epoch 191/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1237 - acc: 0.9641\n",
      "Epoch 192/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1183 - acc: 0.9634\n",
      "Epoch 193/200\n",
      "6154/6154 [==============================] - 0s 22us/step - loss: 0.1173 - acc: 0.9644\n",
      "Epoch 194/200\n",
      "6154/6154 [==============================] - 0s 22us/step - loss: 0.1222 - acc: 0.9625\n",
      "Epoch 195/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1149 - acc: 0.9636\n",
      "Epoch 196/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1151 - acc: 0.9654\n",
      "Epoch 197/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1215 - acc: 0.9626\n",
      "Epoch 198/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1201 - acc: 0.9643\n",
      "Epoch 199/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1293 - acc: 0.9589\n",
      "Epoch 200/200\n",
      "6154/6154 [==============================] - 0s 18us/step - loss: 0.1134 - acc: 0.9662\n",
      "accuracy: 0.988627748294\n",
      "\n",
      "confusion matrix: \n",
      "[[1607    5]\n",
      " [  25 1001]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_dim=X_train.shape[1],activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,epochs=200,batch_size=64)\n",
    "\n",
    "\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred1=[]\n",
    "for i in range(0,len(y_pred)):\n",
    "    y_pred1.append(np.round(y_pred[i][0]))\n",
    "y_pred=np.array(y_pred1,dtype=np.int64)\n",
    "accuracy=accuracy_score(y_pred,y_test)\n",
    "print('accuracy: %s'%accuracy)\n",
    "print()\n",
    "print('confusion matrix: ')\n",
    "cm=confusion_matrix(y_pred,y_test)\n",
    "print(cm)\n",
    "\n",
    "nn_out=[accuracy,'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare=pd.DataFrame(list(zip(RF_out,GB_out,nn_out,)),\n",
    "                     index=pd.Series(['accuracy','auc'], name='metrics'),\n",
    "              columns=['Random Forest','Gradient boosting','Neural network'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient boosting</th>\n",
       "      <th>Neural network</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.953374</td>\n",
       "      <td>0.974981</td>\n",
       "      <td>0.988628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.989547</td>\n",
       "      <td>0.989547</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Random Forest  Gradient boosting Neural network\n",
       "metrics                                                  \n",
       "accuracy       0.953374           0.974981       0.988628\n",
       "auc            0.989547           0.989547             NA"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ora provo a fare il balancing del train e vedere se migliora la prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.externals.joblib.parallel import _backend\n",
    "\n",
    "sm = SMOTE(random_state=0, ratio = 1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.941243366187\n",
      "\n",
      "Confusion matrix:\n",
      "[[1553   76]\n",
      " [  79  930]]\n",
      "\n",
      "auc: 0.98604390812\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RFC=RandomForestClassifier()\n",
    "RFC.fit(X_train,y_train)\n",
    "y_pred=RFC.predict(X_test)\n",
    "\n",
    "#calcolo accuracy\n",
    "accuracy=accuracy_score(y_pred,y_test)\n",
    "print('Accuracy: '+str(accuracy))\n",
    "print()\n",
    "print('Confusion matrix:')\n",
    "cm=confusion_matrix(y_pred,y_test)\n",
    "print(cm)\n",
    "\n",
    "y_pred_proba = RFC.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print()\n",
    "print(\"auc: \"+str(auc))\n",
    "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve Random Forest')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "RF_out_balance=[accuracy,auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRADIENT BOOSTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.971569370735\n",
      "\n",
      "Confusion matrix:\n",
      "[[1573   16]\n",
      " [  59  990]]\n",
      "\n",
      "auc: 0.98604390812\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GB=GradientBoostingClassifier()\n",
    "GB.fit(X_train,y_train)\n",
    "y_pred=GB.predict(X_test)\n",
    "\n",
    "#calcolo accuracy\n",
    "accuracy=accuracy_score(y_pred,y_test)\n",
    "print('Accuracy: '+str(accuracy))\n",
    "print()\n",
    "print('Confusion matrix:')\n",
    "cm=confusion_matrix(y_pred,y_test)\n",
    "print(cm)\n",
    "\n",
    "y_pred_proba = RFC.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print()\n",
    "print(\"auc: \"+str(auc))\n",
    "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve Random Forest')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "GB_out_balance=[accuracy,auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RETE NEURALE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7618/7618 [==============================] - 1s 100us/step - loss: 0.6568 - acc: 0.5692\n",
      "Epoch 2/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.4933 - acc: 0.8670\n",
      "Epoch 3/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.3844 - acc: 0.9014\n",
      "Epoch 4/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.3307 - acc: 0.9076\n",
      "Epoch 5/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.2911 - acc: 0.9086\n",
      "Epoch 6/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.2717 - acc: 0.9233\n",
      "Epoch 7/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.2686 - acc: 0.9197\n",
      "Epoch 8/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.2458 - acc: 0.9252\n",
      "Epoch 9/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.2345 - acc: 0.9282\n",
      "Epoch 10/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.2410 - acc: 0.9268\n",
      "Epoch 11/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.2264 - acc: 0.9323\n",
      "Epoch 12/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.2304 - acc: 0.9279\n",
      "Epoch 13/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.2284 - acc: 0.9303\n",
      "Epoch 14/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.2259 - acc: 0.9350\n",
      "Epoch 15/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.2183 - acc: 0.9327\n",
      "Epoch 16/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.2117 - acc: 0.9346\n",
      "Epoch 17/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.2203 - acc: 0.9316\n",
      "Epoch 18/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.2172 - acc: 0.9313\n",
      "Epoch 19/200\n",
      "7618/7618 [==============================] - 0s 23us/step - loss: 0.2086 - acc: 0.9376\n",
      "Epoch 20/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.2053 - acc: 0.9328\n",
      "Epoch 21/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1976 - acc: 0.9411\n",
      "Epoch 22/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.2074 - acc: 0.9362\n",
      "Epoch 23/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.2037 - acc: 0.9346\n",
      "Epoch 24/200\n",
      "7618/7618 [==============================] - 0s 23us/step - loss: 0.2061 - acc: 0.9370\n",
      "Epoch 25/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1990 - acc: 0.9383\n",
      "Epoch 26/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1910 - acc: 0.9415\n",
      "Epoch 27/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1783 - acc: 0.9459\n",
      "Epoch 28/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1768 - acc: 0.9492\n",
      "Epoch 29/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.2046 - acc: 0.9361\n",
      "Epoch 30/200\n",
      "7618/7618 [==============================] - 0s 24us/step - loss: 0.1832 - acc: 0.9416\n",
      "Epoch 31/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1780 - acc: 0.9458\n",
      "Epoch 32/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1812 - acc: 0.9446\n",
      "Epoch 33/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1795 - acc: 0.9442\n",
      "Epoch 34/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1710 - acc: 0.9476\n",
      "Epoch 35/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1682 - acc: 0.9471\n",
      "Epoch 36/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1784 - acc: 0.9422\n",
      "Epoch 37/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1698 - acc: 0.9501\n",
      "Epoch 38/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1672 - acc: 0.9497\n",
      "Epoch 39/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1785 - acc: 0.9488\n",
      "Epoch 40/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1711 - acc: 0.9467\n",
      "Epoch 41/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1692 - acc: 0.9483\n",
      "Epoch 42/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1785 - acc: 0.9450\n",
      "Epoch 43/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1700 - acc: 0.9464\n",
      "Epoch 44/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1717 - acc: 0.9470\n",
      "Epoch 45/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1667 - acc: 0.9505\n",
      "Epoch 46/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1743 - acc: 0.9422\n",
      "Epoch 47/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1708 - acc: 0.9479\n",
      "Epoch 48/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1714 - acc: 0.9460\n",
      "Epoch 49/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1681 - acc: 0.9471\n",
      "Epoch 50/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1627 - acc: 0.9530\n",
      "Epoch 51/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1592 - acc: 0.9470\n",
      "Epoch 52/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.1736 - acc: 0.9428\n",
      "Epoch 53/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1643 - acc: 0.9470\n",
      "Epoch 54/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1746 - acc: 0.9470\n",
      "Epoch 55/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1754 - acc: 0.9457\n",
      "Epoch 56/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1617 - acc: 0.9496\n",
      "Epoch 57/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1717 - acc: 0.9475\n",
      "Epoch 58/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1621 - acc: 0.9502\n",
      "Epoch 59/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1644 - acc: 0.9489\n",
      "Epoch 60/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1531 - acc: 0.9527\n",
      "Epoch 61/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1609 - acc: 0.9480\n",
      "Epoch 62/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1638 - acc: 0.9489\n",
      "Epoch 63/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1621 - acc: 0.9512\n",
      "Epoch 64/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1671 - acc: 0.9489\n",
      "Epoch 65/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1728 - acc: 0.9463\n",
      "Epoch 66/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1633 - acc: 0.9479\n",
      "Epoch 67/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1663 - acc: 0.9495\n",
      "Epoch 68/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1699 - acc: 0.9447\n",
      "Epoch 69/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1748 - acc: 0.9420\n",
      "Epoch 70/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1656 - acc: 0.9468\n",
      "Epoch 71/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1785 - acc: 0.9468\n",
      "Epoch 72/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1666 - acc: 0.9462\n",
      "Epoch 73/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1608 - acc: 0.9517\n",
      "Epoch 74/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1538 - acc: 0.9520\n",
      "Epoch 75/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1649 - acc: 0.9488\n",
      "Epoch 76/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1602 - acc: 0.9491\n",
      "Epoch 77/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1700 - acc: 0.9480\n",
      "Epoch 78/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1508 - acc: 0.9546\n",
      "Epoch 79/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1606 - acc: 0.9470\n",
      "Epoch 80/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1624 - acc: 0.9480\n",
      "Epoch 81/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1464 - acc: 0.9518\n",
      "Epoch 82/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1520 - acc: 0.9538\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1548 - acc: 0.9517\n",
      "Epoch 84/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1670 - acc: 0.9468\n",
      "Epoch 85/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1568 - acc: 0.9506\n",
      "Epoch 86/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1584 - acc: 0.9497\n",
      "Epoch 87/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1599 - acc: 0.9509\n",
      "Epoch 88/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1665 - acc: 0.9484\n",
      "Epoch 89/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1544 - acc: 0.9548\n",
      "Epoch 90/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1609 - acc: 0.9492\n",
      "Epoch 91/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1499 - acc: 0.9506\n",
      "Epoch 92/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.1573 - acc: 0.9508\n",
      "Epoch 93/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1545 - acc: 0.9534\n",
      "Epoch 94/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1580 - acc: 0.9514\n",
      "Epoch 95/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1502 - acc: 0.9534\n",
      "Epoch 96/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1647 - acc: 0.9481\n",
      "Epoch 97/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1531 - acc: 0.9517\n",
      "Epoch 98/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1651 - acc: 0.9506\n",
      "Epoch 99/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1574 - acc: 0.9500\n",
      "Epoch 100/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1554 - acc: 0.9544\n",
      "Epoch 101/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1674 - acc: 0.9455\n",
      "Epoch 102/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1571 - acc: 0.9497\n",
      "Epoch 103/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1656 - acc: 0.9480\n",
      "Epoch 104/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1580 - acc: 0.9478\n",
      "Epoch 105/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1543 - acc: 0.9518\n",
      "Epoch 106/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1391 - acc: 0.9563\n",
      "Epoch 107/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1571 - acc: 0.9493\n",
      "Epoch 108/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1577 - acc: 0.9517\n",
      "Epoch 109/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1525 - acc: 0.9542\n",
      "Epoch 110/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1600 - acc: 0.9493\n",
      "Epoch 111/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1680 - acc: 0.9487\n",
      "Epoch 112/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.1583 - acc: 0.9499\n",
      "Epoch 113/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1635 - acc: 0.9497\n",
      "Epoch 114/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1587 - acc: 0.9496\n",
      "Epoch 115/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1573 - acc: 0.9502\n",
      "Epoch 116/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1580 - acc: 0.9510\n",
      "Epoch 117/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1600 - acc: 0.9457\n",
      "Epoch 118/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1478 - acc: 0.9523\n",
      "Epoch 119/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1442 - acc: 0.9543\n",
      "Epoch 120/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1515 - acc: 0.9523\n",
      "Epoch 121/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1485 - acc: 0.9508\n",
      "Epoch 122/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1520 - acc: 0.9513\n",
      "Epoch 123/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1567 - acc: 0.9514\n",
      "Epoch 124/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1501 - acc: 0.9543\n",
      "Epoch 125/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1523 - acc: 0.9543\n",
      "Epoch 126/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1602 - acc: 0.9518\n",
      "Epoch 127/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1659 - acc: 0.9481\n",
      "Epoch 128/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1613 - acc: 0.9518\n",
      "Epoch 129/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1535 - acc: 0.9522\n",
      "Epoch 130/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1533 - acc: 0.9531\n",
      "Epoch 131/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1542 - acc: 0.9497\n",
      "Epoch 132/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1528 - acc: 0.9544\n",
      "Epoch 133/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.1469 - acc: 0.9543\n",
      "Epoch 134/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1570 - acc: 0.9526\n",
      "Epoch 135/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1579 - acc: 0.9497\n",
      "Epoch 136/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1464 - acc: 0.9552\n",
      "Epoch 137/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1612 - acc: 0.9501\n",
      "Epoch 138/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1547 - acc: 0.9501\n",
      "Epoch 139/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1686 - acc: 0.9471\n",
      "Epoch 140/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1500 - acc: 0.9523\n",
      "Epoch 141/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1454 - acc: 0.9531\n",
      "Epoch 142/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1586 - acc: 0.9492\n",
      "Epoch 143/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1580 - acc: 0.9449\n",
      "Epoch 144/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1548 - acc: 0.9479\n",
      "Epoch 145/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1577 - acc: 0.9499\n",
      "Epoch 146/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1510 - acc: 0.9517\n",
      "Epoch 147/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1440 - acc: 0.9573\n",
      "Epoch 148/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1622 - acc: 0.9491\n",
      "Epoch 149/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1547 - acc: 0.9509\n",
      "Epoch 150/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1528 - acc: 0.9504\n",
      "Epoch 151/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1534 - acc: 0.9566\n",
      "Epoch 152/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1464 - acc: 0.9530\n",
      "Epoch 153/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1421 - acc: 0.9550\n",
      "Epoch 154/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1435 - acc: 0.9550\n",
      "Epoch 155/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1601 - acc: 0.9464\n",
      "Epoch 156/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1475 - acc: 0.9551\n",
      "Epoch 157/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1572 - acc: 0.9505\n",
      "Epoch 158/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1484 - acc: 0.9496\n",
      "Epoch 159/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1562 - acc: 0.9533\n",
      "Epoch 160/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1497 - acc: 0.9537\n",
      "Epoch 161/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1449 - acc: 0.9517\n",
      "Epoch 162/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1445 - acc: 0.9543\n",
      "Epoch 163/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1444 - acc: 0.9539\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1544 - acc: 0.9523\n",
      "Epoch 165/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1588 - acc: 0.9514\n",
      "Epoch 166/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1558 - acc: 0.9499\n",
      "Epoch 167/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1588 - acc: 0.9493\n",
      "Epoch 168/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1512 - acc: 0.9513\n",
      "Epoch 169/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1580 - acc: 0.9500\n",
      "Epoch 170/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1421 - acc: 0.9555\n",
      "Epoch 171/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1568 - acc: 0.9508\n",
      "Epoch 172/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1588 - acc: 0.9504\n",
      "Epoch 173/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1479 - acc: 0.9517\n",
      "Epoch 174/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1512 - acc: 0.9518\n",
      "Epoch 175/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1488 - acc: 0.9530\n",
      "Epoch 176/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1537 - acc: 0.9493\n",
      "Epoch 177/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1538 - acc: 0.9560\n",
      "Epoch 178/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1597 - acc: 0.9525\n",
      "Epoch 179/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1567 - acc: 0.9489\n",
      "Epoch 180/200\n",
      "7618/7618 [==============================] - 0s 23us/step - loss: 0.1627 - acc: 0.9495\n",
      "Epoch 181/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1571 - acc: 0.9488\n",
      "Epoch 182/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1412 - acc: 0.9571\n",
      "Epoch 183/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1508 - acc: 0.9526\n",
      "Epoch 184/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1522 - acc: 0.9520\n",
      "Epoch 185/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1619 - acc: 0.9492\n",
      "Epoch 186/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1534 - acc: 0.9518\n",
      "Epoch 187/200\n",
      "7618/7618 [==============================] - 0s 24us/step - loss: 0.1514 - acc: 0.9529\n",
      "Epoch 188/200\n",
      "7618/7618 [==============================] - 0s 23us/step - loss: 0.1332 - acc: 0.9573\n",
      "Epoch 189/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1506 - acc: 0.9525\n",
      "Epoch 190/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1435 - acc: 0.9575\n",
      "Epoch 191/200\n",
      "7618/7618 [==============================] - 0s 21us/step - loss: 0.1496 - acc: 0.9531\n",
      "Epoch 192/200\n",
      "7618/7618 [==============================] - 0s 25us/step - loss: 0.1467 - acc: 0.9551\n",
      "Epoch 193/200\n",
      "7618/7618 [==============================] - 0s 22us/step - loss: 0.1476 - acc: 0.9525\n",
      "Epoch 194/200\n",
      "7618/7618 [==============================] - 0s 23us/step - loss: 0.1498 - acc: 0.9501\n",
      "Epoch 195/200\n",
      "7618/7618 [==============================] - 0s 23us/step - loss: 0.1423 - acc: 0.9579\n",
      "Epoch 196/200\n",
      "7618/7618 [==============================] - 0s 25us/step - loss: 0.1523 - acc: 0.9531\n",
      "Epoch 197/200\n",
      "7618/7618 [==============================] - 0s 23us/step - loss: 0.1501 - acc: 0.9560\n",
      "Epoch 198/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1434 - acc: 0.9538\n",
      "Epoch 199/200\n",
      "7618/7618 [==============================] - 0s 19us/step - loss: 0.1449 - acc: 0.9533\n",
      "Epoch 200/200\n",
      "7618/7618 [==============================] - 0s 20us/step - loss: 0.1486 - acc: 0.9505\n",
      "accuracy: 0.985595147839\n",
      "\n",
      "confusion matrix: \n",
      "[[1607   13]\n",
      " [  25  993]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_dim=X_train.shape[1],activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,epochs=200,batch_size=64)\n",
    "\n",
    "\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred1=[]\n",
    "for i in range(0,len(y_pred)):\n",
    "    y_pred1.append(np.round(y_pred[i][0]))\n",
    "y_pred=np.array(y_pred1,dtype=np.int64)\n",
    "accuracy=accuracy_score(y_pred,y_test)\n",
    "print('accuracy: %s'%accuracy)\n",
    "print()\n",
    "print('confusion matrix: ')\n",
    "cm=confusion_matrix(y_pred,y_test)\n",
    "print(cm)\n",
    "\n",
    "nn_out_balance=[accuracy,'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare=pd.DataFrame(list(zip(RF_out,GB_out,nn_out,RF_out_balance,GB_out_balance,nn_out_balance)),\n",
    "                     index=pd.Series(['accuracy','auc'], name='metrics'),\n",
    "              columns=['Random Forest','Gradient boosting','Neural network','Random Forest balanced','Gradient boosting balanced','Neural network balanced'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient boosting</th>\n",
       "      <th>Neural network</th>\n",
       "      <th>Random Forest balanced</th>\n",
       "      <th>Gradient boosting balanced</th>\n",
       "      <th>Neural network balanced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.950341</td>\n",
       "      <td>0.971569</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.941243</td>\n",
       "      <td>0.971569</td>\n",
       "      <td>0.985595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.986528</td>\n",
       "      <td>0.986528</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Random Forest  Gradient boosting Neural network  \\\n",
       "metrics                                                     \n",
       "accuracy       0.950341           0.971569        0.97953   \n",
       "auc            0.986528           0.986528             NA   \n",
       "\n",
       "          Random Forest balanced  Gradient boosting balanced  \\\n",
       "metrics                                                        \n",
       "accuracy                0.941243                    0.971569   \n",
       "auc                     0.986044                    0.986044   \n",
       "\n",
       "         Neural network balanced  \n",
       "metrics                           \n",
       "accuracy                0.985595  \n",
       "auc                           NA  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CROSS VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Stampa dei risultati \n",
      "Tree k-fold CV-error: 0.937101\n",
      "Confusion matrix:\n",
      "[[5233  208]\n",
      " [ 294 3057]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "RFC = RandomForestClassifier()\n",
    "scores = cross_val_score(RFC, X, y, cv=5)\n",
    "# stampe\n",
    "print('\\n Stampa dei risultati ')\n",
    "print('Tree k-fold CV-error: %f' % scores.mean())\n",
    "\n",
    "# k-fold cross-validation --> stima Y\n",
    "predicted = cross_val_predict(RFC, X, y, cv=5)\n",
    "\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Stampa dei risultati \n",
      "Tree k-fold CV-error: 0.970996\n",
      "Confusion matrix:\n",
      "[[5271  170]\n",
      " [  85 3266]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "RFC = GradientBoostingClassifier()\n",
    "scores = cross_val_score(RFC, X, y, cv=5)\n",
    "# stampe\n",
    "print('\\n Stampa dei risultati ')\n",
    "print('Tree k-fold CV-error: %f' % scores.mean())\n",
    "\n",
    "# k-fold cross-validation --> stima Y\n",
    "predicted = cross_val_predict(RFC, X, y, cv=5)\n",
    "\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTI**\n",
    "... brevi cenni sull'analisi fatta..\n",
    "\n",
    "Gli algoritmi applicati sono essenzaialmente tre:\n",
    "+ Random Forest\n",
    "+ Gradien boosting\n",
    "+ rete neurale\n",
    "\n",
    "Una volta fatto il fitting dei dati mediante i tre algoritmi abbiamo riportato in tabella per ognuno di essi quelle che sono le metriche di confronto più comuni:\n",
    "- Accuracy\n",
    "- Roc curve e auc (area under the curve)\n",
    "\n",
    "I tre algoritmi sono stati provati su:\n",
    "+ dataset pulito, splittato in train e test (HOLD OUT)\n",
    "+ dataset pulito, splittato in train e test (HOLD OUT) con train bilanciato\n",
    "+ dataset pulito, non splittato in train e test, ma utilizzando la cross validation\n",
    "\n",
    "Ho scelto di comparare la \"semplicità\" e la maggior interpretabilità dei \"Decision trees\" con la complessità delle reti neurali, spesso definite come \"Black box\" per il procedimento non limpido che si cela dietro la classificazione.\n",
    "\n",
    "Sicuramente sia il *Random forest* che il *Gradient boosting* sono più performanti rispetto ai  classici decision trees in quanto uno step fondamentale di questi algoritmi è il **Bagging**:\n",
    "- cioè vengono presi piu samples di Bootstrap dal dataset (train) e vengono creati degli alberi e quindi fatto il fit per ognuno di essi e poi fatta la media delle prediction degli  \"M1,...,Mb\" modelli.\n",
    "\n",
    "Bootstrap + aggregation $\\rightarrow$ Bagging\n",
    "\n",
    "Nonostante le elevate performance di entrambi i modelli, la rete neurale sembra comunque fare una predizione più accurata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
